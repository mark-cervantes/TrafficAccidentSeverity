{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11: AdaBoost Classifier Model\n",
    "\n",
    "This notebook focuses on developing, tuning, and evaluating an AdaBoost classifier for predicting severe traffic accidents.\n",
    "\n",
    "**PRD References:** 3.1.5.6 (AdaBoost), FR3 (Model Training & Tuning), 9.1 (Jupyter Notebooks), 9.3 (Performance Logging), 10.5 (Hyperparameter Logging)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "from pathlib import Path\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Ensure src directory is in Python path\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier # Default base estimator for AdaBoost\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Custom utilities\n",
    "from modeling_utils import compute_classification_metrics, append_performance_record\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = Path.cwd().parent / 'data'\n",
    "PROCESSED_DATA_FILE = DATA_DIR / 'processed' / 'preprocessed_data.csv'\n",
    "MODELS_DIR = Path.cwd().parent / 'models'\n",
    "REPORTS_DIR = Path.cwd().parent / 'reports'\n",
    "PERFORMANCE_EXCEL_FILE = REPORTS_DIR / 'model_performance_summary.xlsx'\n",
    "RANDOM_STATE = 42\n",
    "MODEL_NAME = 'AdaBoost'\n",
    "CV_SHEET_NAME = f'{MODEL_NAME}_CV_Trials'\n",
    "MODEL_FILENAME = f'{MODEL_NAME.lower().replace(\" \", \"_\")}_best_model.joblib'\n",
    "\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "REPORTS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "\n",
    "Load the preprocessed data. Ensure that the target variable `SEVERITY` and all features are correctly identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully: (22072, 44)\n",
      "Features shape: (22072, 43), Target shape: (22072,)\n",
      "Target distribution:\n",
      "SEVERITY\n",
      "0    0.931859\n",
      "1    0.068141\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv(PROCESSED_DATA_FILE)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Processed data file not found at {PROCESSED_DATA_FILE}\")\n",
    "    print(\"Please ensure '02_data_preprocessing.ipynb' has been run successfully.\")\n",
    "    df = None\n",
    "\n",
    "if df is not None:\n",
    "    print(f\"Data loaded successfully: {df.shape}\")\n",
    "    if 'SEVERITY' not in df.columns:\n",
    "        print(\"Error: Target column 'SEVERITY' not found in the dataframe.\")\n",
    "        X, y = None, None\n",
    "    else:\n",
    "        X = df.drop('SEVERITY', axis=1)\n",
    "        y = df['SEVERITY']\n",
    "        print(f\"Features shape: {X.shape}, Target shape: {y.shape}\")\n",
    "        print(f\"Target distribution:\\n{y.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train-Test Split\n",
    "\n",
    "Split the data into training and testing sets, stratifying by the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (17657, 43), y_train shape: (17657,)\n",
      "X_test shape: (4415, 43), y_test shape: (4415,)\n"
     ]
    }
   ],
   "source": [
    "if X is not None and y is not None:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "else:\n",
    "    print(\"Skipping train-test split as data was not loaded properly.\")\n",
    "    X_train, X_test, y_train, y_test = None, None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Handle Class Imbalance\n",
    "\n",
    "AdaBoost itself does not have a `class_weight` parameter. If using a base estimator that supports it (like `DecisionTreeClassifier`), it can be set there. The default base estimator is `DecisionTreeClassifier(max_depth=1)`. The algorithm inherently gives more weight to misclassified instances in subsequent iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Definition and Hyperparameter Tuning (GridSearchCV)\n",
    "\n",
    "We'll use GridSearchCV to find the best hyperparameters for the AdaBoost model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GridSearchCV for AdaBoost...\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=1, learning_rate=1.0, n_estimators=50; total time=   1.5s\n",
      "[CV] END estimator__max_depth=1, learning_rate=0.1, n_estimators=50; total time=   1.7s\n",
      "[CV] END estimator__max_depth=1, learning_rate=0.1, n_estimators=50; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=1, learning_rate=1.0, n_estimators=50; total time=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=1, learning_rate=1.0, n_estimators=50; total time=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=1, learning_rate=0.1, n_estimators=50; total time=   2.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=1, learning_rate=1.0, n_estimators=100; total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=2, learning_rate=0.1, n_estimators=50; total time=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=1, learning_rate=0.1, n_estimators=100; total time=   4.0s\n",
      "[CV] END estimator__max_depth=1, learning_rate=0.1, n_estimators=100; total time=   4.1s\n",
      "[CV] END estimator__max_depth=2, learning_rate=0.1, n_estimators=50; total time=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=1, learning_rate=1.0, n_estimators=100; total time=   4.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END estimator__max_depth=2, learning_rate=0.1, n_estimators=50; total time=   3.3s\n",
      "[CV] END estimator__max_depth=2, learning_rate=1.0, n_estimators=50; total time=   2.3s\n",
      "[CV] END estimator__max_depth=1, learning_rate=1.0, n_estimators=100; total time=   5.4s\n",
      "[CV] END estimator__max_depth=1, learning_rate=0.1, n_estimators=100; total time=   5.6s\n",
      "[CV] END estimator__max_depth=2, learning_rate=1.0, n_estimators=50; total time=   2.5s\n",
      "[CV] END estimator__max_depth=2, learning_rate=1.0, n_estimators=50; total time=   2.4s\n",
      "[CV] END estimator__max_depth=2, learning_rate=0.1, n_estimators=100; total time=   5.1s\n",
      "[CV] END estimator__max_depth=2, learning_rate=0.1, n_estimators=100; total time=   4.8s\n",
      "[CV] END estimator__max_depth=2, learning_rate=0.1, n_estimators=100; total time=   6.0s\n",
      "[CV] END estimator__max_depth=2, learning_rate=1.0, n_estimators=100; total time=   4.0s\n",
      "[CV] END estimator__max_depth=2, learning_rate=1.0, n_estimators=100; total time=   3.9s\n",
      "[CV] END estimator__max_depth=2, learning_rate=1.0, n_estimators=100; total time=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The parameter 'algorithm' is deprecated in 1.6 and has no effect. It will be removed in version 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV completed in 12.10 seconds.\n",
      "Best F1 score from GridSearchCV: 0.9013\n",
      "Best parameters from GridSearchCV: {'estimator__max_depth': 2, 'learning_rate': 1.0, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "if X_train is not None:\n",
    "    # Base estimator for AdaBoost. Default is DecisionTreeClassifier(max_depth=1)\n",
    "    # We can tune parameters of this base estimator as well.\n",
    "    # For simplicity in the fast grid, we might use the default or a slightly deeper tree.\n",
    "    base_estimator = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "    ada_classifier = AdaBoostClassifier(estimator=base_estimator, random_state=RANDOM_STATE, algorithm='SAMME') # Using SAMME algorithm with decision tree\n",
    "\n",
    "    # Define a parameter grid\n",
    "    # Note: AdaBoost's `learning_rate` shrinks the contribution of each classifier.\n",
    "    # `n_estimators` is the number of weak learners to train iteratively.\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
    "        'estimator__max_depth': [1, 2, 3], # Max depth of the base Decision Tree\n",
    "        'estimator__class_weight': [None, 'balanced'] # If base estimator supports it\n",
    "    }\n",
    "\n",
    "    # Define a smaller, more focused parameter grid for faster initial run\n",
    "    param_grid_fast = {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [0.1, 1.0],\n",
    "        'estimator__max_depth': [1, 2] # Default base is max_depth=1\n",
    "        # 'estimator__class_weight': [None] # Keeping it simple for fast grid\n",
    "    }\n",
    "\n",
    "    # Custom ROC AUC scorer to ensure predict_proba is used\n",
    "    def roc_auc_proba_scorer(estimator, X_data, y_true_data):\n",
    "        y_proba = estimator.predict_proba(X_data)[:, 1]\n",
    "        return roc_auc_score(y_true_data, y_proba, average='weighted', multi_class='ovr')\n",
    "\n",
    "    scoring = {\n",
    "        'F1': make_scorer(f1_score, average='weighted'),\n",
    "        'ROC_AUC': roc_auc_proba_scorer, \n",
    "        'Precision': make_scorer(precision_score, average='weighted', zero_division=0),\n",
    "        'Recall': make_scorer(recall_score, average='weighted', zero_division=0)\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=ada_classifier,\n",
    "        param_grid=param_grid_fast, # Using the fast grid for quicker execution\n",
    "        scoring=scoring,\n",
    "        refit='F1', # Refit the best model using F1 score\n",
    "        cv=3,       # Number of cross-validation folds (3 for quicker run)\n",
    "        verbose=2,\n",
    "        n_jobs=-1   # Use all available cores\n",
    "    )\n",
    "\n",
    "    print(f\"Starting GridSearchCV for {MODEL_NAME}...\")\n",
    "    start_time_grid_search = time.time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    end_time_grid_search = time.time()\n",
    "    grid_search_duration = end_time_grid_search - start_time_grid_search\n",
    "    print(f\"GridSearchCV completed in {grid_search_duration:.2f} seconds.\")\n",
    "\n",
    "    print(f\"Best F1 score from GridSearchCV: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Best parameters from GridSearchCV: {grid_search.best_params_}\")\n",
    "else:\n",
    "    print(\"Skipping GridSearchCV as training data is not available.\")\n",
    "    grid_search = None\n",
    "    grid_search_duration = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Log Hyperparameter Tuning Experiments\n",
    "\n",
    "Log each hyperparameter combination tried by GridSearchCV and its performance to the Excel sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging 8 CV trials to Excel sheet 'AdaBoost_CV_Trials'...\n",
      "CV trials logging complete.\n"
     ]
    }
   ],
   "source": [
    "if grid_search is not None and hasattr(grid_search, 'cv_results_'):\n",
    "    cv_results = grid_search.cv_results_\n",
    "    print(f\"Logging {len(cv_results['params'])} CV trials to Excel sheet '{CV_SHEET_NAME}'...\")\n",
    "\n",
    "    for i in range(len(cv_results['params'])):\n",
    "        params_tried = cv_results['params'][i]\n",
    "        record = {\n",
    "            'Model': MODEL_NAME,\n",
    "            'Sheet_Context': 'CV_Trial',\n",
    "            'Hyperparameter_Set_Tried': json.dumps(params_tried),\n",
    "            'CV_F1_Mean': cv_results.get('mean_test_F1', [np.nan]*len(cv_results['params']))[i],\n",
    "            'CV_F1_Std': cv_results.get('std_test_F1', [np.nan]*len(cv_results['params']))[i],\n",
    "            'CV_ROC_AUC_Mean': cv_results.get('mean_test_ROC_AUC', [np.nan]*len(cv_results['params']))[i],\n",
    "            'CV_ROC_AUC_Std': cv_results.get('std_test_ROC_AUC', [np.nan]*len(cv_results['params']))[i],\n",
    "            'CV_Precision_Mean': cv_results.get('mean_test_Precision', [np.nan]*len(cv_results['params']))[i],\n",
    "            'CV_Precision_Std': cv_results.get('std_test_Precision', [np.nan]*len(cv_results['params']))[i],\n",
    "            'CV_Recall_Mean': cv_results.get('mean_test_Recall', [np.nan]*len(cv_results['params']))[i],\n",
    "            'CV_Recall_Std': cv_results.get('std_test_Recall', [np.nan]*len(cv_results['params']))[i],\n",
    "            'CV_Rank_F1': cv_results.get('rank_test_F1', [np.nan]*len(cv_results['params']))[i],\n",
    "            'Fit_Time_Seconds_Mean': cv_results.get('mean_fit_time', [np.nan]*len(cv_results['params']))[i]\n",
    "        }\n",
    "        append_performance_record(PERFORMANCE_EXCEL_FILE, record, sheet_name=CV_SHEET_NAME)\n",
    "    print(\"CV trials logging complete.\")\n",
    "else:\n",
    "    print(\"Skipping CV trials logging as GridSearchCV results are not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Best Model Evaluation and Logging\n",
    "\n",
    "Evaluate the best model found by GridSearchCV on the training and test sets, then log its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost Model Performance:\n",
      "Training Set Metrics: {'Precision': 0.92038658614506, 'Recall': 0.9332842498725717, 'F1': 0.903867969119115, 'ROC_AUC': np.float64(0.714503776416501)}\n",
      "Test Set Metrics: {'Precision': 0.8915249752945081, 'Recall': 0.9311438278595696, 'F1': 0.8998947216586578, 'ROC_AUC': np.float64(0.6936160779899121)}\n",
      "Final model performance logged.\n",
      "Best AdaBoost model saved to /home/cmark/Projects/TrafficAccidentSeverity/models/adaboost_best_model.joblib\n"
     ]
    }
   ],
   "source": [
    "if grid_search is not None and hasattr(grid_search, 'best_estimator_') and X_train is not None:\n",
    "    best_ada_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Predictions\n",
    "    y_train_pred = best_ada_model.predict(X_train)\n",
    "    y_train_prob = best_ada_model.predict_proba(X_train)[:, 1]\n",
    "    y_test_pred = best_ada_model.predict(X_test)\n",
    "    y_test_prob = best_ada_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Compute metrics\n",
    "    train_metrics = compute_classification_metrics(y_train, y_train_pred, y_train_prob)\n",
    "    test_metrics = compute_classification_metrics(y_test, y_test_pred, y_test_prob)\n",
    "\n",
    "    print(f\"Best {MODEL_NAME} Model Performance:\")\n",
    "    print(f\"Training Set Metrics: {train_metrics}\")\n",
    "    print(f\"Test Set Metrics: {test_metrics}\")\n",
    "\n",
    "    # Log final model performance\n",
    "    final_record = {\n",
    "        'Model': MODEL_NAME,\n",
    "        'Sheet_Context': 'Final_Model',\n",
    "        'Selected_Final_Hyperparameters': json.dumps(best_params),\n",
    "        'Training_Time_Seconds': grid_search_duration, # Total GridSearchCV time as proxy\n",
    "        'Train_Precision': train_metrics.get('Precision'),\n",
    "        'Train_Recall': train_metrics.get('Recall'),\n",
    "        'Train_F1': train_metrics.get('F1'),\n",
    "        'Train_ROC_AUC': train_metrics.get('ROC_AUC'),\n",
    "        'Test_Precision': test_metrics.get('Precision'),\n",
    "        'Test_Recall': test_metrics.get('Recall'),\n",
    "        'Test_F1': test_metrics.get('F1'),\n",
    "        'Test_ROC_AUC': test_metrics.get('ROC_AUC'),\n",
    "        'CV_Best_F1_Score': grid_search.best_score_\n",
    "    }\n",
    "    append_performance_record(PERFORMANCE_EXCEL_FILE, final_record, sheet_name='Model_Summaries')\n",
    "    print(\"Final model performance logged.\")\n",
    "\n",
    "    # Save the best model\n",
    "    model_save_path = MODELS_DIR / MODEL_FILENAME\n",
    "    joblib.dump(best_ada_model, model_save_path)\n",
    "    print(f\"Best {MODEL_NAME} model saved to {model_save_path}\")\n",
    "else:\n",
    "    print(\"Skipping final model evaluation, logging, and saving as prerequisites are not met.\")\n",
    "    best_ada_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "This notebook implemented and tuned an AdaBoost classifier. The hyperparameter tuning process was logged, and the best performing model was evaluated and saved. Its performance metrics are recorded in the summary Excel sheet for comparison with other models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic-severity",
   "language": "python",
   "name": "trafficseverity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
