{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model Implementation\n",
    "\n",
    "**Objective:** Implement, train, evaluate, and tune a Logistic Regression model for predicting severe traffic accidents.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Preprocessed data file (`data/processed/preprocessed_data.csv`).\n",
    "- Utility functions from `src/modeling_utils.py` and `src/preprocessing_utils.py`.\n",
    "\n",
    "**Key Libraries Imported:**\n",
    "- Pandas\n",
    "- NumPy\n",
    "- Scikit-learn\n",
    "- Matplotlib\n",
    "- Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from: ../data/processed/preprocessed_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import json\n",
    "from modeling_utils import init_performance_excel, append_performance_record, init_performance_excel\n",
    "from preprocessing_utils import load_raw_data, drop_outcome_columns, drop_identifiers, parse_datetime, extract_temporal_features, impute_missing_categorical, encode_categorical, parse_desc_features, save_preprocessed\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Conditional path logic for data file\n",
    "if 'COLAB_GPU' in os.environ:\n",
    "    # Running in Google Colab\n",
    "    try:\n",
    "        from google.colab import drive\n",
    "        drive.mount('/content/drive', force_remount=True)\n",
    "    except ImportError:\n",
    "        print(\"Google Colab module not available. Ensure this code is running in Google Colab.\")\n",
    "    data_path = '/content/drive/MyDrive/Colab_Notebooks/TrafficAccidentSeverity/data/processed/preprocessed_data.csv'\n",
    "else:\n",
    "    # Running locally (Jupyter Lab or other)\n",
    "    data_path = '../data/processed/preprocessed_data.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Successfully loaded data from: {data_path}\")\n",
    "    from modeling_utils import init_performance_excel, append_performance_record\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file not found at {data_path}\")\n",
    "    if 'COLAB_GPU' in os.environ:\n",
    "        print(\"Please ensure the file exists in your Google Drive at the specified path and that Drive is mounted.\")\n",
    "    else:\n",
    "        print(\"Please ensure the file exists at the specified relative path for your local environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target variable\n",
    "X = df.drop(['SEVERITY'], axis=1)  # Drop only target variable as datetime has already been processed\n",
    "y = df['SEVERITY']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Encode categorical features\n",
    "X_train_encoded = pd.get_dummies(X_train, drop_first=True)\n",
    "X_test_encoded = pd.get_dummies(X_test, drop_first=True)\n",
    "\n",
    "# Align columns of test set with training set\n",
    "X_test_encoded = X_test_encoded.reindex(columns=X_train_encoded.columns, fill_value=0)\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      4114\n",
      "           1       0.00      0.00      0.00       301\n",
      "\n",
      "    accuracy                           0.93      4415\n",
      "   macro avg       0.47      0.50      0.48      4415\n",
      "weighted avg       0.87      0.93      0.90      4415\n",
      "\n",
      "ROC AUC Score: 0.6779\n"
     ]
    }
   ],
   "source": [
    "# Initialize Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42, solver='liblinear', multi_class='ovr')\n",
    "\n",
    "# Train the model\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "y_prob_all_classes = log_reg.predict_proba(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate ROC AUC score robustly for binary or multiclass cases\n",
    "if y_prob_all_classes.shape[1] == 2:  # Binary classification\n",
    "\t# roc_auc_score expects probabilities of the positive class\n",
    "\troc_auc = roc_auc_score(y_test, y_prob_all_classes[:, 1])\n",
    "else:  # Multiclass classification\n",
    "\troc_auc = roc_auc_score(y_test, y_prob_all_classes, multi_class='ovr', average='weighted')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/cmark/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.01, 'solver': 'liblinear'}\n",
      "Best CV ROC AUC Score (ovr): 0.6527\n",
      "Training Time: 296.38 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grids for different solvers\n",
    "param_grid = [\n",
    "    {\n",
    "        'solver': ['liblinear'], # Solvers that don't need high max_iter and support L1/L2\n",
    "        'C': [0.01, 0.1, 1, 10, 100]\n",
    "        # Note: liblinear can be faster for small data, but only handles L1/L2\n",
    "    },\n",
    "    {\n",
    "        'solver': ['lbfgs', 'newton-cg'], # General-purpose solvers, often converge fast\n",
    "        'C': [0.01, 0.1, 1, 10, 100]\n",
    "        # max_iter is usually not the bottleneck for these unless the problem is very complex\n",
    "    },\n",
    "    {\n",
    "        'solver': ['sag', 'saga'], # Solvers for larger datasets, require more iterations\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'max_iter': [1000, 5000, 10000] # Add higher max_iter values for sag/saga\n",
    "        # You might need even higher values depending on your data size and complexity.\n",
    "        # Let's also explicitly set the tolerance, although increasing max_iter is usually sufficient.\n",
    "        # 'tol': [1e-4, 1e-3] # Optional: Decrease tolerance for stricter convergence if needed\n",
    "    }\n",
    "]\n",
    "# Define alternate param_grid for fastest iteration meant for testing that can be trained for just few seconds\n",
    "param_grid_fast = [\n",
    "    {\n",
    "        'solver': ['liblinear'], # Solvers that don't need high max_iter and support L1/L2\n",
    "        'C': [0.01, 0.1, 1]\n",
    "        # Note: liblinear can be faster for small data, but only handles L1/L2\n",
    "    },\n",
    "    {\n",
    "        'solver': ['lbfgs', 'newton-cg'], # General-purpose solvers, often converge fast\n",
    "        'C': [0.01, 0.1, 1]\n",
    "        # max_iter is usually not the bottleneck for these unless the problem is very complex\n",
    "    },\n",
    "    {\n",
    "        'solver': ['sag', 'saga'], # Solvers for larger datasets, require more iterations\n",
    "        'C': [0.01, 0.1, 1],\n",
    "        'max_iter': [100] # Add higher max_iter values for sag/saga\n",
    "        # You might need even higher values depending on your data size and complexity.\n",
    "        # Let's also explicitly set the tolerance, although increasing max_iter is usually sufficient.\n",
    "        # 'tol': [1e-4, 1e-3] # Optional: Decrease tolerance for stricter convergence if needed\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Initialize GridSearchCV with the updated param_grid (list of dicts)\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(random_state=42),\n",
    "    param_grid, # param_grid is now a list of dicts\n",
    "    cv=5,\n",
    "    scoring='roc_auc_ovr', # Keep the multi-class scoring from the previous step\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Record end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Get best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best CV ROC AUC Score (ovr): {best_score:.4f}\")\n",
    "print(f\"Training Time: {training_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging Hyperparameter Trials & Results\n",
    "> with xlsx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cmark/Projects/TrafficAccidentSeverity/src/modeling_utils.py:142: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, pd.DataFrame([record])], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Define the Excel file path\n",
    "excel_filepath = '../reports/model_performance_summary.xlsx'\n",
    "\n",
    "# Initialize the Excel file if it doesn't exist\n",
    "init_performance_excel(excel_filepath)\n",
    "\n",
    "# Prepare the record to append\n",
    "record = {\n",
    "    'Model_Name': 'Logistic Regression',\n",
    "    'Hyperparameter_Set_Tried': json.dumps(param_grid),\n",
    "    'CV_Score_for_Set': best_score,\n",
    "    'Selected_Final_Hyperparameters': json.dumps(best_params),\n",
    "    'Training_Time_Seconds': training_time,\n",
    "    'Train_Precision': precision,\n",
    "    'Train_Recall': recall,\n",
    "    'Train_F1': f1,\n",
    "    'Train_ROC_AUC': roc_auc\n",
    "}\n",
    "\n",
    "# Append the record to the Excel file\n",
    "append_performance_record(excel_filepath, record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression model saved to: ../models/logistic_regression_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Define the model save path\n",
    "model_save_path = '../models/logistic_regression_best_model.pkl'\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(grid_search.best_estimator_, model_save_path)\n",
    "\n",
    "print(f\"Best Logistic Regression model saved to: {model_save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic-severity",
   "language": "python",
   "name": "trafficseverity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
