{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08: LightGBM Model for Severe Traffic Accident Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective:** Implement, tune, and evaluate a LightGBM classifier to predict severe traffic accidents on EDSA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup: Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12d8a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Imbalanced-learn (if SMOTE or other techniques are used)\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.pipeline import Pipeline as ImbPipeline # To avoid conflict with sklearn.pipeline\n",
    "\n",
    "# Project-specific utilities\n",
    "import sys\n",
    "sys.path.append('../src') # Add src directory to Python path\n",
    "from modeling_utils import compute_classification_metrics, append_performance_record, init_performance_excel\n",
    "\n",
    "# Visualization (optional, for EDA within notebook if needed)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure Pandas display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "# Configure Matplotlib/Seaborn for inline plotting\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53536807",
   "metadata": {},
   "source": [
    "### 1.1 Constants and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0528273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATA_PATH = '../data/processed/preprocessed_data.csv'\n",
    "MODEL_SAVE_PATH = '../models/lightgbm_best_model.joblib'\n",
    "PERFORMANCE_EXCEL_PATH = '../reports/model_performance_summary.xlsx'\n",
    "MODEL_NAME = 'LightGBM'\n",
    "\n",
    "RANDOM_STATE = 42 # For reproducibility\n",
    "CV_FOLDS = 5 # Number of cross-validation folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4495f010",
   "metadata": {},
   "source": [
    "### 1.2 Initialize Performance Excel (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4c7e841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel log file '../reports/model_performance_summary.xlsx' already exists.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pd.read_excel(PERFORMANCE_EXCEL_PATH)\n",
    "    print(f\"Excel log file '{PERFORMANCE_EXCEL_PATH}' already exists.\")\n",
    "except FileNotFoundError:\n",
    "    init_performance_excel(PERFORMANCE_EXCEL_PATH)\n",
    "    print(f\"Initialized Excel log file at '{PERFORMANCE_EXCEL_PATH}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842588e9",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9ea02b",
   "metadata": {},
   "source": [
    "### 2.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39d891ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from ../data/processed/preprocessed_data.csv\n",
      "Shape of the dataframe: (22072, 42)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEVERITY</th>\n",
       "      <th>Y</th>\n",
       "      <th>X</th>\n",
       "      <th>DATETIME_UTC</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>season</th>\n",
       "      <th>ROAD_EDSA</th>\n",
       "      <th>MAIN_CAUSE_Human error</th>\n",
       "      <th>MAIN_CAUSE_Other (see description)</th>\n",
       "      <th>MAIN_CAUSE_Road defect</th>\n",
       "      <th>MAIN_CAUSE_Unknown</th>\n",
       "      <th>MAIN_CAUSE_Vehicle defect</th>\n",
       "      <th>COLLISION_TYPE_Angle Impact</th>\n",
       "      <th>COLLISION_TYPE_Head-On</th>\n",
       "      <th>COLLISION_TYPE_Hit Object</th>\n",
       "      <th>COLLISION_TYPE_Multiple</th>\n",
       "      <th>COLLISION_TYPE_No Collision Stated</th>\n",
       "      <th>COLLISION_TYPE_Rear-End</th>\n",
       "      <th>COLLISION_TYPE_Self-Accident</th>\n",
       "      <th>COLLISION_TYPE_Side Swipe</th>\n",
       "      <th>WEATHER_Unknown</th>\n",
       "      <th>WEATHER_clear-day</th>\n",
       "      <th>WEATHER_clear-night</th>\n",
       "      <th>WEATHER_cloudy</th>\n",
       "      <th>WEATHER_fog</th>\n",
       "      <th>WEATHER_partly-cloudy-day</th>\n",
       "      <th>WEATHER_partly-cloudy-night</th>\n",
       "      <th>WEATHER_rain</th>\n",
       "      <th>LIGHT_Unknown</th>\n",
       "      <th>LIGHT_day</th>\n",
       "      <th>LIGHT_dusk</th>\n",
       "      <th>LIGHT_night</th>\n",
       "      <th>REPORTING_AGENCY_MMDA Metrobase</th>\n",
       "      <th>REPORTING_AGENCY_MMDA Road Safety Unit</th>\n",
       "      <th>REPORTING_AGENCY_Other</th>\n",
       "      <th>desc_word_count</th>\n",
       "      <th>desc_contains_collision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Property</td>\n",
       "      <td>14.65771</td>\n",
       "      <td>121.01979</td>\n",
       "      <td>2014-06-30 05:40:00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "      <td>False</td>\n",
       "      <td>Summer</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Property</td>\n",
       "      <td>14.65771</td>\n",
       "      <td>121.01979</td>\n",
       "      <td>2014-03-17 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>False</td>\n",
       "      <td>Spring</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Injury</td>\n",
       "      <td>14.65771</td>\n",
       "      <td>121.01979</td>\n",
       "      <td>2013-11-26 02:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>2013</td>\n",
       "      <td>False</td>\n",
       "      <td>Fall</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Property</td>\n",
       "      <td>14.65771</td>\n",
       "      <td>121.01979</td>\n",
       "      <td>2013-10-26 13:00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>True</td>\n",
       "      <td>Fall</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Injury</td>\n",
       "      <td>14.65771</td>\n",
       "      <td>121.01966</td>\n",
       "      <td>2013-06-26 23:30:00</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>False</td>\n",
       "      <td>Summer</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEVERITY        Y         X         DATETIME_UTC  hour  day_of_week  day  \\\n",
       "0  Property 14.65771 121.01979  2014-06-30 05:40:00     5            0   30   \n",
       "1  Property 14.65771 121.01979  2014-03-17 01:00:00     1            0   17   \n",
       "2    Injury 14.65771 121.01979  2013-11-26 02:00:00     2            1   26   \n",
       "3  Property 14.65771 121.01979  2013-10-26 13:00:00    13            5   26   \n",
       "4    Injury 14.65771 121.01966  2013-06-26 23:30:00    23            2   26   \n",
       "\n",
       "   month  year  is_weekend  season  ROAD_EDSA  MAIN_CAUSE_Human error  \\\n",
       "0      6  2014       False  Summer       True                    True   \n",
       "1      3  2014       False  Spring       True                    True   \n",
       "2     11  2013       False    Fall       True                    True   \n",
       "3     10  2013        True    Fall       True                    True   \n",
       "4      6  2013       False  Summer       True                    True   \n",
       "\n",
       "   MAIN_CAUSE_Other (see description)  MAIN_CAUSE_Road defect  \\\n",
       "0                               False                   False   \n",
       "1                               False                   False   \n",
       "2                               False                   False   \n",
       "3                               False                   False   \n",
       "4                               False                   False   \n",
       "\n",
       "   MAIN_CAUSE_Unknown  MAIN_CAUSE_Vehicle defect  COLLISION_TYPE_Angle Impact  \\\n",
       "0               False                      False                        False   \n",
       "1               False                      False                        False   \n",
       "2               False                      False                        False   \n",
       "3               False                      False                        False   \n",
       "4               False                      False                        False   \n",
       "\n",
       "   COLLISION_TYPE_Head-On  COLLISION_TYPE_Hit Object  COLLISION_TYPE_Multiple  \\\n",
       "0                   False                      False                    False   \n",
       "1                   False                      False                    False   \n",
       "2                   False                      False                    False   \n",
       "3                   False                      False                    False   \n",
       "4                   False                      False                    False   \n",
       "\n",
       "   COLLISION_TYPE_No Collision Stated  COLLISION_TYPE_Rear-End  \\\n",
       "0                                True                    False   \n",
       "1                                True                    False   \n",
       "2                                True                    False   \n",
       "3                                True                    False   \n",
       "4                                True                    False   \n",
       "\n",
       "   COLLISION_TYPE_Self-Accident  COLLISION_TYPE_Side Swipe  WEATHER_Unknown  \\\n",
       "0                         False                      False             True   \n",
       "1                         False                      False             True   \n",
       "2                         False                      False             True   \n",
       "3                         False                      False             True   \n",
       "4                         False                      False             True   \n",
       "\n",
       "   WEATHER_clear-day  WEATHER_clear-night  WEATHER_cloudy  WEATHER_fog  \\\n",
       "0              False                False           False        False   \n",
       "1              False                False           False        False   \n",
       "2              False                False           False        False   \n",
       "3              False                False           False        False   \n",
       "4              False                False           False        False   \n",
       "\n",
       "   WEATHER_partly-cloudy-day  WEATHER_partly-cloudy-night  WEATHER_rain  \\\n",
       "0                      False                        False         False   \n",
       "1                      False                        False         False   \n",
       "2                      False                        False         False   \n",
       "3                      False                        False         False   \n",
       "4                      False                        False         False   \n",
       "\n",
       "   LIGHT_Unknown  LIGHT_day  LIGHT_dusk  LIGHT_night  \\\n",
       "0           True      False       False        False   \n",
       "1           True      False       False        False   \n",
       "2           True      False       False        False   \n",
       "3           True      False       False        False   \n",
       "4           True      False       False        False   \n",
       "\n",
       "   REPORTING_AGENCY_MMDA Metrobase  REPORTING_AGENCY_MMDA Road Safety Unit  \\\n",
       "0                            False                                    True   \n",
       "1                            False                                    True   \n",
       "2                            False                                    True   \n",
       "3                            False                                    True   \n",
       "4                            False                                    True   \n",
       "\n",
       "   REPORTING_AGENCY_Other  desc_word_count  desc_contains_collision  \n",
       "0                   False               30                        1  \n",
       "1                   False               38                        1  \n",
       "2                   False               30                        1  \n",
       "3                   False               31                        1  \n",
       "4                   False               32                        1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(PROCESSED_DATA_PATH)\n",
    "print(f\"Data loaded successfully from {PROCESSED_DATA_PATH}\")\n",
    "print(f\"Shape of the dataframe: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e08e55",
   "metadata": {},
   "source": [
    "### 2.2 Feature and Target Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac568a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (22072, 41)\n",
      "Target shape: (22072,)\n",
      "Target distribution:\n",
      "SEVERITY\n",
      "Property   0.93127\n",
      "Injury     0.06773\n",
      "Fatal      0.00100\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "TARGET_COLUMN = 'SEVERITY' # Assuming this is the target column name\n",
    "X = df.drop(columns=[TARGET_COLUMN])\n",
    "y = df[TARGET_COLUMN]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cc2071",
   "metadata": {},
   "source": [
    "### 2.3 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e38588e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (17657, 41), y_train shape: (17657,)\n",
      "X_test shape: (4415, 41), y_test shape: (4415,)\n",
      "Training target distribution:\n",
      "SEVERITY\n",
      "Property   0.93125\n",
      "Injury     0.06774\n",
      "Fatal      0.00102\n",
      "Name: proportion, dtype: float64\n",
      "Test target distribution:\n",
      "SEVERITY\n",
      "Property   0.93137\n",
      "Injury     0.06772\n",
      "Fatal      0.00091\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=RANDOM_STATE, \n",
    "    stratify=y # Ensure stratification for imbalanced datasets\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "print(f\"Training target distribution:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"Test target distribution:\\n{y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4cf48d",
   "metadata": {},
   "source": [
    "### 2.4 Numerical Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5f275af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling complete.\n",
      "X_train_scaled (numerical features) head:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>desc_word_count</th>\n",
       "      <th>desc_contains_collision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7948</th>\n",
       "      <td>-0.97779</td>\n",
       "      <td>0.21942</td>\n",
       "      <td>-0.80840</td>\n",
       "      <td>1.64366</td>\n",
       "      <td>-1.19811</td>\n",
       "      <td>-0.70811</td>\n",
       "      <td>-1.75055</td>\n",
       "      <td>0.69034</td>\n",
       "      <td>-0.73554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17297</th>\n",
       "      <td>1.27048</td>\n",
       "      <td>-0.00204</td>\n",
       "      <td>-0.65935</td>\n",
       "      <td>-0.44388</td>\n",
       "      <td>0.86189</td>\n",
       "      <td>1.10753</td>\n",
       "      <td>-0.18682</td>\n",
       "      <td>-0.61884</td>\n",
       "      <td>-0.73554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3678</th>\n",
       "      <td>-1.25551</td>\n",
       "      <td>-0.47388</td>\n",
       "      <td>0.98016</td>\n",
       "      <td>-1.48766</td>\n",
       "      <td>-0.28256</td>\n",
       "      <td>1.10753</td>\n",
       "      <td>0.20411</td>\n",
       "      <td>-0.18245</td>\n",
       "      <td>-0.73554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6054</th>\n",
       "      <td>-0.68120</td>\n",
       "      <td>0.71897</td>\n",
       "      <td>0.38397</td>\n",
       "      <td>-0.44388</td>\n",
       "      <td>1.66300</td>\n",
       "      <td>-1.01072</td>\n",
       "      <td>0.98597</td>\n",
       "      <td>0.03575</td>\n",
       "      <td>-0.73554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13923</th>\n",
       "      <td>1.31281</td>\n",
       "      <td>-1.19265</td>\n",
       "      <td>0.23493</td>\n",
       "      <td>0.59989</td>\n",
       "      <td>1.66300</td>\n",
       "      <td>1.10753</td>\n",
       "      <td>0.59504</td>\n",
       "      <td>0.90853</td>\n",
       "      <td>1.35955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Y        X     hour  day_of_week      day    month     year  \\\n",
       "7948  -0.97779  0.21942 -0.80840      1.64366 -1.19811 -0.70811 -1.75055   \n",
       "17297  1.27048 -0.00204 -0.65935     -0.44388  0.86189  1.10753 -0.18682   \n",
       "3678  -1.25551 -0.47388  0.98016     -1.48766 -0.28256  1.10753  0.20411   \n",
       "6054  -0.68120  0.71897  0.38397     -0.44388  1.66300 -1.01072  0.98597   \n",
       "13923  1.31281 -1.19265  0.23493      0.59989  1.66300  1.10753  0.59504   \n",
       "\n",
       "       desc_word_count  desc_contains_collision  \n",
       "7948           0.69034                 -0.73554  \n",
       "17297         -0.61884                 -0.73554  \n",
       "3678          -0.18245                 -0.73554  \n",
       "6054           0.03575                 -0.73554  \n",
       "13923          0.90853                  1.35955  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Identify numerical features (assuming all non-object columns are numerical and need scaling)\n",
    "numerical_features = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "scaler = StandardScaler() # Or MinMaxScaler()\n",
    "\n",
    "# Create copies of the dataframes to store the scaled features\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "# Fit the scaler on the training data's numerical features and transform both training and test set's numerical features\n",
    "if numerical_features:\n",
    "    X_train_scaled[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
    "    X_test_scaled[numerical_features] = scaler.transform(X_test[numerical_features])\n",
    "    print(\"\\nScaling complete.\")\n",
    "    print(\"X_train_scaled (numerical features) head:\")\n",
    "    display(X_train_scaled[numerical_features].head())\n",
    "else:\n",
    "    print(\"\\nNo numerical features identified for scaling.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef19375",
   "metadata": {},
   "source": [
    "### 2.5 Class Imbalance Handling (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1ee0a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated scale_pos_weight: 13.75 (Negative: 16443, Positive: 1196)\n",
      "\n",
      "Using X_train_final shape: (17657, 41), y_train_final shape: (17657,)\n",
      "y_train_final distribution:\n",
      "SEVERITY\n",
      "Property   0.93125\n",
      "Injury     0.06774\n",
      "Fatal      0.00102\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_267646/5684601.py:30: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  neg_count = y_train_final.value_counts().get(0, 0) # Get count for class 0, default to 0 if not present\n",
      "/tmp/ipykernel_267646/5684601.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  pos_count = y_train_final.value_counts().get(1, 0) # Get count for class 1, default to 0 if not present\n"
     ]
    }
   ],
   "source": [
    "# Class imbalance was identified as a potential issue.\n",
    "# Strategy chosen in '04_modeling_pipeline_setup.ipynb' should be applied here if it involves resampling.\n",
    "# LightGBM also has built-in parameters like `is_unbalance=True` or `scale_pos_weight` that can be effective.\n",
    "\n",
    "# Option 1: Using SMOTE (if chosen as the strategy)\n",
    "# Ensure 'imblearn' is installed: pip install imbalanced-learn\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# smote = SMOTE(random_state=RANDOM_STATE)\n",
    "# X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# print(\"Original training dataset shape:\", y_train.value_counts())\n",
    "# print(\"Resampled training dataset shape (SMOTE):\", y_train_resampled.value_counts())\n",
    "\n",
    "# # If using SMOTE, subsequent training should use X_train_resampled and y_train_resampled\n",
    "# X_train_final = X_train_resampled\n",
    "# y_train_final = y_train_resampled\n",
    "\n",
    "# Option 2: Relying on LightGBM's built-in handling (e.g., scale_pos_weight or is_unbalance=True)\n",
    "# In this case, we use the scaled training data directly.\n",
    "# The `scale_pos_weight` will be calculated and used during model instantiation if this path is chosen.\n",
    "# Or, `is_unbalance=True` can be set in LGBMClassifier.\n",
    "\n",
    "X_train_final = X_train_scaled.copy() # Make a copy to avoid modifying the original scaled data\n",
    "y_train_final = y_train.copy()\n",
    "\n",
    "# Calculate scale_pos_weight for later use if LightGBM's parameter is preferred\n",
    "# scale_pos_weight = number_of_negative_samples / number_of_positive_samples\n",
    "if len(y_train_final.value_counts()) > 1:\n",
    "    neg_count = y_train_final.value_counts().get(0, 0) # Get count for class 0, default to 0 if not present\n",
    "    pos_count = y_train_final.value_counts().get(1, 0) # Get count for class 1, default to 0 if not present\n",
    "    if pos_count > 0:\n",
    "        calculated_scale_pos_weight = neg_count / pos_count\n",
    "        print(f\"Calculated scale_pos_weight: {calculated_scale_pos_weight:.2f} (Negative: {neg_count}, Positive: {pos_count})\")\n",
    "    else:\n",
    "        print(\"Positive class count is zero, cannot calculate scale_pos_weight.\")\n",
    "        calculated_scale_pos_weight = 1 # Default or handle as appropriate\n",
    "else:\n",
    "    print(\"Target variable has only one class. Check data or stratification.\")\n",
    "    calculated_scale_pos_weight = 1 # Default or handle as appropriate\n",
    "\n",
    "# For now, we'll proceed with X_train_final and y_train_final.\n",
    "# The choice of applying SMOTE vs. using LGBM parameters will be reflected in the model training step.\n",
    "print(f\"\\nUsing X_train_final shape: {X_train_final.shape}, y_train_final shape: {y_train_final.shape}\")\n",
    "print(f\"y_train_final distribution:\\n{y_train_final.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7c2b11",
   "metadata": {},
   "source": [
    "## 3. Initial LightGBM Model (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18426e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting baseline LightGBM model training...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 676\n",
      "[LightGBM] [Info] Number of data points in the train set: 17657, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score -6.888516\n",
      "[LightGBM] [Info] Start training from score -2.692150\n",
      "[LightGBM] [Info] Start training from score -0.071232\n",
      "Baseline model training completed in 4.27 seconds.\n",
      "\n",
      "Baseline Model Performance:\n",
      "Training Metrics (Baseline):\n",
      "  Precision: 0.9489\n",
      "  Recall: 0.9462\n",
      "  F1: 0.9293\n",
      "  ROC_AUC: 0.9567\n",
      "\n",
      "Test Metrics (Baseline):\n",
      "  Precision: 0.9020\n",
      "  Recall: 0.9311\n",
      "  F1: 0.9028\n",
      "  ROC_AUC: 0.7043\n",
      "\n",
      "Baseline model performance logged to ../reports/model_performance_summary.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_267646/1117715307.py:58: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"Timestamp\": datetime.utcnow().isoformat(),\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting baseline LightGBM model training...\")\n",
    "\n",
    "# Ensure X_train_final and y_train_final are defined\n",
    "if \"X_train_final\" not in globals():\n",
    "    # This implies X_train_scaled should be defined earlier\n",
    "    X_train_final = X_train_scaled.copy()\n",
    "if \"y_train_final\" not in globals():\n",
    "    # This implies y_train should be defined earlier\n",
    "    y_train_final = y_train.copy()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "lgbm_baseline = lgb.LGBMClassifier(random_state=RANDOM_STATE)\n",
    "\n",
    "columns_to_drop = [\"DATETIME_UTC\", \"season\"]\n",
    "X_train_final_numeric = X_train_final.drop(\n",
    "    columns=columns_to_drop, errors=\"ignore\"\n",
    ")\n",
    "X_test_scaled_numeric = X_test_scaled.drop(\n",
    "    columns=columns_to_drop, errors=\"ignore\"\n",
    ")\n",
    "\n",
    "lgbm_baseline.fit(X_train_final_numeric, y_train_final)\n",
    "\n",
    "# Make predictions using only the numeric features\n",
    "y_pred_train_baseline = lgbm_baseline.predict(X_train_final_numeric)\n",
    "y_pred_test_baseline = lgbm_baseline.predict(X_test_scaled_numeric)\n",
    "\n",
    "# For ROC AUC, pass the full probability matrix for multiclass\n",
    "y_prob_train_baseline = lgbm_baseline.predict_proba(X_train_final_numeric)\n",
    "y_prob_test_baseline = lgbm_baseline.predict_proba(X_test_scaled_numeric)\n",
    "\n",
    "training_time_baseline = time.time() - start_time\n",
    "print(\n",
    "    f\"Baseline model training completed in {training_time_baseline:.2f} seconds.\"\n",
    ")\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"\\nBaseline Model Performance:\")\n",
    "# This assumes compute_classification_metrics is now the updated version\n",
    "train_metrics_baseline = compute_classification_metrics(\n",
    "    y_train_final, y_pred_train_baseline, y_prob_train_baseline\n",
    ")\n",
    "print(\"Training Metrics (Baseline):\")\n",
    "for metric, value in train_metrics_baseline.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "test_metrics_baseline = compute_classification_metrics(\n",
    "    y_test, y_pred_test_baseline, y_prob_test_baseline\n",
    ")\n",
    "print(\"\\nTest Metrics (Baseline):\")\n",
    "for metric, value in test_metrics_baseline.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# Log to Excel\n",
    "baseline_record = {\n",
    "    \"Model_Name\": f\"{MODEL_NAME}_Baseline\",\n",
    "    \"Timestamp\": datetime.utcnow().isoformat(),\n",
    "    \"Hyperparameter_Set_Tried\": \"Default\",\n",
    "    \"CV_Score_for_Set\": None,  # No CV for baseline\n",
    "    \"Selected_Final_Hyperparameters\": json.dumps(lgbm_baseline.get_params()),\n",
    "    \"Training_Time_Seconds\": training_time_baseline,\n",
    "    \"Train_Precision\": train_metrics_baseline.get(\"Precision\"),\n",
    "    \"Train_Recall\": train_metrics_baseline.get(\"Recall\"),\n",
    "    \"Train_F1\": train_metrics_baseline.get(\"F1\"),\n",
    "    \"Train_ROC_AUC\": train_metrics_baseline.get(\"ROC_AUC\"),\n",
    "    \"Test_Precision\": test_metrics_baseline.get(\"Precision\"),\n",
    "    \"Test_Recall\": test_metrics_baseline.get(\"Recall\"),\n",
    "    \"Test_F1\": test_metrics_baseline.get(\"F1\"),\n",
    "    \"Test_ROC_AUC\": test_metrics_baseline.get(\"ROC_AUC\"),\n",
    "    \"Class_Imbalance_Strategy\": \"Default params (is_unbalance=False, no scale_pos_weight unless manually set above)\",\n",
    "    \"Notes\": \"Initial baseline model without hyperparameter tuning.\",\n",
    "}\n",
    "\n",
    "# append_performance_record(PERFORMANCE_EXCEL_PATH, baseline_record) # Uncomment when ready\n",
    "print(f\"\\nBaseline model performance logged to {PERFORMANCE_EXCEL_PATH}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db9d7e3",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d679859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for hyperparameter tuning (e.g., GridSearchCV or RandomizedSearchCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da93db",
   "metadata": {},
   "source": [
    "### 4.1 Define Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8186f974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter grid for LightGBM defined:\n",
      "  n_estimators: [100, 200, 300, 500]\n",
      "  learning_rate: [0.01, 0.05, 0.1]\n",
      "  num_leaves: [20, 31, 40, 50]\n",
      "  max_depth: [-1, 10, 20]\n",
      "  reg_alpha: [0, 0.1, 0.5, 1]\n",
      "  reg_lambda: [0, 0.1, 0.5, 1]\n",
      "  colsample_bytree: [0.7, 0.8, 0.9, 1.0]\n",
      "  subsample: [0.7, 0.8, 0.9, 1.0]\n",
      "  min_child_samples: [10, 20, 30]\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid for LightGBM\n",
    "# This is an example grid; adjust based on computational resources and desired search space.\n",
    "param_grid_lgbm = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [20, 31, 40, 50], # Default is 31\n",
    "    'max_depth': [-1, 10, 20], # -1 means no limit\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1], # L1 regularization\n",
    "    'reg_lambda': [0, 0.1, 0.5, 1], # L2 regularization\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0], # Subsample ratio of columns when constructing each tree\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0], # Subsample ratio of the training instance\n",
    "    'min_child_samples': [10, 20, 30], # Minimum number of data needed in a child (leaf)\n",
    "    # 'scale_pos_weight': [1, calculated_scale_pos_weight], # If not using SMOTE and want to tune this\n",
    "    # 'is_unbalance': [True, False] # If not using SMOTE and want to tune this\n",
    "}\n",
    "\n",
    "print(\"Parameter grid for LightGBM defined:\")\n",
    "for key, value in param_grid_lgbm.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c3b3db",
   "metadata": {},
   "source": [
    "### 4.2 Perform Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabefaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RandomizedSearchCV for LightGBM with 5 iterations...\n",
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 2.223655 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 677\n",
      "[LightGBM] [Info] Number of data points in the train set: 14125, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score -6.916644\n",
      "[LightGBM] [Info] Start training from score -2.691898\n",
      "[LightGBM] [Info] Start training from score -0.071220\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 4.814076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 672\n",
      "[LightGBM] [Info] Number of data points in the train set: 14125, number of used features: 29\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 5.332142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 677\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 5.191492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 677\n",
      "[LightGBM] [Info] Start training from score -6.916644\n",
      "[LightGBM] [Info] Start training from score -2.691898\n",
      "[LightGBM] [Info] Number of data points in the train set: 14126, number of used features: 32\n",
      "[LightGBM] [Info] Number of data points in the train set: 14125, number of used features: 32\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 5.329171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 678\n",
      "[LightGBM] [Info] Start training from score -0.071220\n",
      "[LightGBM] [Info] Start training from score -6.847722\n",
      "[LightGBM] [Info] Number of data points in the train set: 14126, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score -6.916644\n",
      "[LightGBM] [Info] Start training from score -2.691898\n",
      "[LightGBM] [Info] Start training from score -2.691969\n",
      "[LightGBM] [Info] Start training from score -6.916715\n",
      "[LightGBM] [Info] Start training from score -0.071291\n",
      "[LightGBM] [Info] Start training from score -0.071220\n",
      "[LightGBM] [Info] Start training from score -2.691969\n",
      "[LightGBM] [Info] Start training from score -0.071215\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 6.240357 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 678\n",
      "[LightGBM] [Info] Number of data points in the train set: 14125, number of used features: 32\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 6.623339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 678\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 6.656731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 678\n",
      "[LightGBM] [Info] Start training from score -6.916644\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 3.647876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 678\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 5.158279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 671\n",
      "[LightGBM] [Info] Number of data points in the train set: 14125, number of used features: 32\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 6.321167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 677\n",
      "[LightGBM] [Info] Number of data points in the train set: 14126, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score -2.691898\n",
      "[LightGBM] [Info] Number of data points in the train set: 14126, number of used features: 32\n",
      "[LightGBM] [Info] Number of data points in the train set: 14125, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score -6.916644\n",
      "[LightGBM] [Info] Start training from score -6.847722\n",
      "[LightGBM] [Info] Number of data points in the train set: 14126, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score -0.071220\n",
      "[LightGBM] [Info] Start training from score -6.916715\n",
      "[LightGBM] [Info] Start training from score -2.691898\n",
      "[LightGBM] [Info] Start training from score -6.916644\n",
      "[LightGBM] [Info] Start training from score -6.847722\n",
      "[LightGBM] [Info] Start training from score -2.693014\n",
      "[LightGBM] [Info] Start training from score -2.691969\n",
      "[LightGBM] [Info] Start training from score -2.691898\n",
      "[LightGBM] [Info] Start training from score -0.071220\n",
      "[LightGBM] [Info] Start training from score -2.691969\n",
      "[LightGBM] [Info] Start training from score -0.071215\n",
      "[LightGBM] [Info] Start training from score -0.071215\n",
      "[LightGBM] [Info] Start training from score -0.071220\n",
      "[LightGBM] [Info] Start training from score -0.071291\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 6.971509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 678\n",
      "[LightGBM] [Info] Number of data points in the train set: 14126, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score -6.847722\n",
      "[LightGBM] [Info] Start training from score -2.693014\n",
      "[LightGBM] [Info] Start training from score -0.071215\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mStarting RandomizedSearchCV for LightGBM with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN_ITER_RANDOM_SEARCH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m iterations...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     37\u001b[39m search_start_time = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mrandom_search_lgbm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_final_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_final\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m search_time = time.time() - search_start_time\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRandomizedSearchCV completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/joblib/parallel.py:2071\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2065\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2071\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/joblib/parallel.py:1681\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1678\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1680\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1681\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1683\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1684\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/TrafficAccidentSeverity/.venv/lib/python3.12/site-packages/joblib/parallel.py:1799\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1789\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1794\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1797\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1798\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1799\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1800\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1802\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1803\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1810\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Initialize LightGBM classifier for tuning\n",
    "lgbm_tuning = lgb.LGBMClassifier(random_state=RANDOM_STATE, n_jobs=-1)\n",
    "\n",
    "# Define scoring meLightGBMtrics. F1 is often good for imbalanced classes.\n",
    "# Using make_scorer to ensure predict_proba is not required for some metrics if not available/needed by them.\n",
    "scoring = {\n",
    "    'F1': make_scorer(f1_score, average='weighted', zero_division=0),\n",
    "    'ROC_AUC': make_scorer(roc_auc_score, needs_proba=True, average='weighted'), # Ensure predict_proba is used\n",
    "    'Precision': make_scorer(precision_score, average='weighted', zero_division=0),\n",
    "    'Recall': make_scorer(recall_score, average='weighted', zero_division=0)\n",
    "}\n",
    "\n",
    "# Using RandomizedSearchCV for potentially faster search over a large grid.\n",
    "# For a smaller grid or more exhaustive search, GridSearchCV can be used.\n",
    "N_ITER_RANDOM_SEARCH = 1#  # Number of parameter settings that are sampled. Adjust as needed.\n",
    "# N_ITER_RANDOM_SEARCH = 2 # Reduced for quick testing\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Create filtered datasets that remove problematic columns for LightGBM\n",
    "columns_to_drop = [\"DATETIME_UTC\", \"season\"]\n",
    "X_train_final_numeric = X_train_final.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "random_search_lgbm = RandomizedSearchCV(\n",
    "    estimator=lgbm_tuning,\n",
    "    param_distributions=param_grid_lgbm,\n",
    "    n_iter=N_ITER_RANDOM_SEARCH,\n",
    "    scoring=scoring,\n",
    "    refit='F1', # Refit the best estimator using F1 score\n",
    "    cv=cv_strategy,\n",
    "    verbose=2, # Set to 1 or higher for more messages\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1 # Use all available cores for CV fits\n",
    ")\n",
    "\n",
    "print(f\"Starting RandomizedSearchCV for LightGBM with {N_ITER_RANDOM_SEARCH} iterations...\")\n",
    "search_start_time = time.time()\n",
    "random_search_lgbm.fit(X_train_final_numeric, y_train_final)\n",
    "search_time = time.time() - search_start_time\n",
    "print(f\"RandomizedSearchCV completed in {search_time:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b513d1",
   "metadata": {},
   "source": [
    "### 4.3 Log All CV Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0be50520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging all CV trials to Excel...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mLogging all CV trials to Excel...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m cv_results_df = pd.DataFrame(\u001b[43mrandom_search_lgbm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcv_results_\u001b[49m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Iterate through each trial and log it\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(cv_results_df)):\n",
      "\u001b[31mAttributeError\u001b[39m: 'RandomizedSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "print(\"\\nLogging all CV trials to Excel...\")\n",
    "cv_results_df = pd.DataFrame(random_search_lgbm.cv_results_)\n",
    "\n",
    "# Iterate through each trial and log it\n",
    "for i in range(len(cv_results_df)):\n",
    "    params_tried = cv_results_df.loc[i, 'params']\n",
    "    # The main score used for refit (e.g., 'mean_test_F1')\n",
    "    # The exact name depends on the 'refit' string and how RandomizedSearchCV stores it.\n",
    "    # It's usually 'mean_test_{refit_metric_name}'\n",
    "    cv_score_for_set = cv_results_df.loc[i, f'mean_test_{random_search_lgbm.refit_}'] \n",
    "\n",
    "    trial_record = {\n",
    "        'Model_Name': f\"{MODEL_NAME}_CV_Trial\",\n",
    "        'Timestamp': datetime.utcnow().isoformat(),\n",
    "        'Hyperparameter_Set_Tried': json.dumps(params_tried),\n",
    "        'CV_Score_for_Set': cv_score_for_set,\n",
    "        'Selected_Final_Hyperparameters': None, # Not applicable for individual trials\n",
    "        'Training_Time_Seconds': cv_results_df.loc[i, 'mean_fit_time'], # Average fit time for this param set\n",
    "        'Train_Precision': None, 'Train_Recall': None, 'Train_F1': None, 'Train_ROC_AUC': None, # Not typically available per trial from CV results directly\n",
    "        'Test_Precision': None, 'Test_Recall': None, 'Test_F1': None, 'Test_ROC_AUC': None, # These are for the final model\n",
    "        'Class_Imbalance_Strategy': 'Refer to final model section or if scale_pos_weight/is_unbalance in params_tried', # Or specify if varied in grid\n",
    "        'Notes': f\"CV trial {i+1}/{N_ITER_RANDOM_SEARCH}. Scorer: {random_search_lgbm.refit_}.\"\n",
    "    }\n",
    "    append_performance_record(PERFORMANCE_EXCEL_PATH, trial_record)\n",
    "\n",
    "print(f\"All {len(cv_results_df)} CV trials logged to {PERFORMANCE_EXCEL_PATH}\")\n",
    "print(\"\\nTop 5 CV results (based on F1 score):\")\n",
    "display(cv_results_df.sort_values(by=f'rank_test_{random_search_lgbm.refit_}').head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad0ebc8",
   "metadata": {},
   "source": [
    "### 4.4 Best Parameters and Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99aac5cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m best_params_lgbm = \u001b[43mrandom_search_lgbm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbest_params_\u001b[49m\n\u001b[32m      2\u001b[39m best_score_lgbm = random_search_lgbm.best_score_\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest Hyperparameters found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'RandomizedSearchCV' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "best_params_lgbm = random_search_lgbm.best_params_\n",
    "best_score_lgbm = random_search_lgbm.best_score_\n",
    "\n",
    "print(f\"Best Hyperparameters found for {MODEL_NAME}:\")\n",
    "print(json.dumps(best_params_lgbm, indent=2))\n",
    "print(f\"\\nBest CV Score ({random_search_lgbm.refit_}): {best_score_lgbm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29ce1c",
   "metadata": {},
   "source": [
    "## 5. Final Model Training & Evaluation (with Best Hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e5da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining final LightGBM model with best hyperparameters...\")\n",
    "start_time_final_model = time.time()\n",
    "\n",
    "# Instantiate the final model with the best parameters\n",
    "# Note: RandomizedSearchCV automatically refits the best estimator on the whole training data (used for CV)\n",
    "# So, random_search_lgbm.best_estimator_ is already trained.\n",
    "lgbm_final = random_search_lgbm.best_estimator_\\n\n",
    "\n",
    "# If you wanted to train it explicitly (e.g., if refit=False or for clarity):\n",
    "# lgbm_final = lgb.LGBMClassifier(**best_params_lgbm, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "# lgbm_final.fit(X_train_final, y_train_final)\n",
    "\n",
    "training_time_final_model = time.time() - start_time_final_model # This would be training time if explicitly fit\n",
    "# If using best_estimator_, the 'training time' is more complex as it includes CV search time.\n",
    "# For simplicity, we can log the search_time or the refit time if available, or time for this cell if re-fitting.\n",
    "# Here, we'll assume 'search_time' captured the bulk of the effort for finding the best model.\n",
    "print(f\"Final model (best_estimator_ from RandomizedSearch) obtained. Search took {search_time:.2f} seconds.\")\n",
    "\n",
    "# Make predictions with the final model\n",
    "y_pred_train_final = lgbm_final.predict(X_train_final)\n",
    "y_pred_test_final = lgbm_final.predict(X_test_scaled)\n",
    "\n",
    "y_prob_train_final = lgbm_final.predict_proba(X_train_final)[:, 1]\n",
    "y_prob_test_final = lgbm_final.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluate final model performance\n",
    "print(\"\\nFinal Model Performance:\")\n",
    "train_metrics_final = compute_classification_metrics(y_train_final, y_pred_train_final, y_prob_train_final)\n",
    "print(\"Training Metrics (Final Model):\")\n",
    "for metric, value in train_metrics_final.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "test_metrics_final = compute_classification_metrics(y_test, y_pred_test_final, y_prob_test_final)\n",
    "print(\"\\nTest Metrics (Final Model):\")\n",
    "for metric, value in test_metrics_final.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# Determine Class Imbalance Strategy string for logging\n",
    "imbalance_strategy_note = \"Default LightGBM params or manually set\"\n",
    "if 'scale_pos_weight' in best_params_lgbm and best_params_lgbm['scale_pos_weight'] is not None and best_params_lgbm['scale_pos_weight'] != 1:\n",
    "    imbalance_strategy_note = f\"scale_pos_weight={best_params_lgbm['scale_pos_weight']:.2f}\"\n",
    "elif 'is_unbalance' in best_params_lgbm and best_params_lgbm['is_unbalance'] == True:\n",
    "    imbalance_strategy_note = \"is_unbalance=True\"\n",
    "# If SMOTE was applied to X_train_final, that would be the primary strategy.\n",
    "# For this template, we assume X_train_final was either original or SMOTE'd, and LGBM params are secondary/alternative.\n",
    "# Modify this logic if SMOTE was used to create X_train_final.\n",
    "\n",
    "# Log final model performance to Excel\n",
    "final_model_record = {\n",
    "    'Model_Name': f\"{MODEL_NAME}_Tuned\",\n",
    "    'Timestamp': datetime.utcnow().isoformat(),\n",
    "    'Hyperparameter_Set_Tried': f\"RandomizedSearchCV_iters={N_ITER_RANDOM_SEARCH}\",\n",
    "    'CV_Score_for_Set': best_score_lgbm, # Best score from CV\n",
    "    'Selected_Final_Hyperparameters': json.dumps(best_params_lgbm),\n",
    "    'Training_Time_Seconds': search_time, # Using total search time as a proxy for effort to get best model\n",
    "    'Train_Precision': train_metrics_final.get('Precision'),\n",
    "    'Train_Recall': train_metrics_final.get('Recall'),\n",
    "    'Train_F1': train_metrics_final.get('F1'),\n",
    "    'Train_ROC_AUC': train_metrics_final.get('ROC_AUC'),\n",
    "    'Test_Precision': test_metrics_final.get('Precision'),\n",
    "    'Test_Recall': test_metrics_final.get('Recall'),\n",
    "    'Test_F1': test_metrics_final.get('F1'),\n",
    "    'Test_ROC_AUC': test_metrics_final.get('ROC_AUC'),\n",
    "    'Class_Imbalance_Strategy': imbalance_strategy_note, # Reflect actual strategy based on best_params or if SMOTE was used\n",
    "    'Notes': f\"Final model after RandomizedSearchCV with {N_ITER_RANDOM_SEARCH} iterations. Refit on F1.\"\n",
    "}\n",
    "\n",
    "append_performance_record(PERFORMANCE_EXCEL_PATH, final_model_record)\n",
    "print(f\"\\nFinal model performance logged to {PERFORMANCE_EXCEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed33f766",
   "metadata": {},
   "source": [
    "## 6. Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1f0bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nSaving the final tuned LightGBM model to {MODEL_SAVE_PATH}...\")\n",
    "try:\n",
    "    # Ensure the directory exists\n",
    "    import os\n",
    "    os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
    "    \n",
    "    joblib.dump(lgbm_final, MODEL_SAVE_PATH)\n",
    "    print(f\"Model successfully saved to {MODEL_SAVE_PATH}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2612510d",
   "metadata": {},
   "source": [
    "## 7. Conclusion and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86af98c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"## 7. Conclusion and Summary\")\n",
    "print(\"--- \")\n",
    "print(f\"The LightGBM model development process is now complete for notebook {MODEL_NAME}.\")\n",
    "print(\"Key steps included:\")\n",
    "print(\"- Data loading, preprocessing (splitting, scaling). \")\n",
    "print(\"- Addressed class imbalance (details in section 2.5 and model parameters). \")\n",
    "print(\"- Trained a baseline LightGBM model and logged its performance. \")\n",
    "print(f\"- Performed hyperparameter tuning using RandomizedSearchCV with {N_ITER_RANDOM_SEARCH} iterations and {CV_FOLDS}-fold CV, optimizing for F1 score.\")\n",
    "print(\"- Logged all CV trials and the best hyperparameters found.\")\n",
    "print(f\"Best hyperparameters: {json.dumps(best_params_lgbm)}\")\n",
    "print(f\"Best CV F1 score: {best_score_lgbm:.4f}\")\n",
    "print(\"- Trained and evaluated the final model using these best hyperparameters.\")\n",
    "print(\"Final Model Test Performance:\")\n",
    "for metric, value in test_metrics_final.items():\n",
    "    print(f\"  - Test {metric}: {value:.4f}\")\n",
    "print(f\"- Saved the final tuned model to: {MODEL_SAVE_PATH}\")\n",
    "print(f\"- All performance metrics and hyperparameter trials have been logged to: {PERFORMANCE_EXCEL_PATH}\")\n",
    "print(\"\\nFurther analysis should involve comparing this model's performance against other models developed in this project.\")\n",
    "print(\"Consider factors like interpretability (e.g., feature importances from LightGBM), training time, and specific business requirements when selecting the overall best model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic-severity",
   "language": "python",
   "name": "trafficseverity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 6
}
