{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9525158",
   "metadata": {},
   "source": [
    "# 04. Modeling Pipeline Setup: Train-Test Split & Scaling\n",
    "\n",
    "**Objective:** Load preprocessed data, perform a stratified train-test split with a fixed random seed, apply numerical scaling, and initialize the performance logging infrastructure.\n",
    "\n",
    "**PRD References:** 3.1.5, 3.1.7, 9.3, 10.5; **NFR2**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafbc97a",
   "metadata": {},
   "source": [
    "## 1. Imports and Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d74f253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE  # added for class imbalance handling\n",
    "from modeling_utils import (\n",
    "    compute_classification_metrics,\n",
    "    init_performance_excel,\n",
    "    append_performance_record\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6722ff05",
   "metadata": {},
   "source": [
    "## 2. Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f931a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded preprocessed data: 22072 rows, 42 columns\n"
     ]
    }
   ],
   "source": [
    "# Load the fully preprocessed dataset\n",
    "data_path = '../data/processed/preprocessed_data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "print(f\"Loaded preprocessed data: {df.shape[0]} rows, {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eec0215",
   "metadata": {},
   "source": [
    "## 3. Define Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1a83078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "target_col = 'SEVERITY'\n",
    "feature_cols = [c for c in df.columns if c != target_col]\n",
    "X = df[feature_cols]\n",
    "y = df[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1812ab40",
   "metadata": {},
   "source": [
    "## 4. Stratified Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b825ede9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 17657 rows\n",
      "Test set:  4415 rows\n"
     ]
    }
   ],
   "source": [
    "# Perform stratified split to preserve class distribution\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "print(f\"Train set: {X_train.shape[0]} rows\")\n",
    "print(f\"Test set:  {X_test.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f7cb53",
   "metadata": {},
   "source": [
    "## 5. Numerical Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6ae5b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled numerical features on training and test sets.\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical features for scaling\n",
    "num_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Initialize scaler and fit on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[num_features] = scaler.fit_transform(X_train[num_features])\n",
    "X_test_scaled[num_features] = scaler.transform(X_test[num_features])\n",
    "\n",
    "print(\"Scaled numerical features on training and test sets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9903ab0",
   "metadata": {},
   "source": [
    "## 6. Initialize Performance Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bab04d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized performance log at ../reports/model_performance_summary.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Create Excel for logging model performance\n",
    "performance_file = '../reports/model_performance_summary.xlsx'\n",
    "init_performance_excel(performance_file)\n",
    "print(f\"Initialized performance log at {performance_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de777506",
   "metadata": {},
   "source": [
    "## 7. Class Imbalance Handling\n",
    "\n",
    "Apply SMOTE to generate synthetic samples for the minority class in the training data. This helps mitigate class imbalance before model training. (PRD 3.1.7, 11.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdf7b379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before SMOTE:\n",
      "SEVERITY\n",
      "Property    0.931245\n",
      "Injury      0.067735\n",
      "Fatal       0.001019\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class distribution after SMOTE:\n",
      "SEVERITY\n",
      "Property    0.333333\n",
      "Injury      0.333333\n",
      "Fatal       0.333333\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Before resampling, display class distribution\n",
    "print(\"Class distribution before SMOTE:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "# Exclude non-numeric columns from resampling\n",
    "X_train_numeric = X_train_scaled.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_numeric, y_train)\n",
    "\n",
    "# Add back non-numeric columns to the resampled dataset\n",
    "X_train_resampled = pd.concat(\n",
    "\t[pd.DataFrame(X_train_resampled, columns=X_train_numeric.columns), \n",
    "\t X_train_scaled.drop(columns=X_train_numeric.columns).reset_index(drop=True)], \n",
    "\taxis=1\n",
    ")\n",
    "\n",
    "# After resampling, display new distribution\n",
    "print(\"\\nClass distribution after SMOTE:\")\n",
    "print(y_train_resampled.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016cb3ed",
   "metadata": {},
   "source": [
    "**Next Steps:**\n",
    "- Use `X_train_resampled` and `y_train_resampled` for model training and hyperparameter tuning (Commit 14+).\n",
    "- Evaluate models on the untouched `X_test_scaled`, `y_test`. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic-severity",
   "language": "python",
   "name": "trafficseverity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
