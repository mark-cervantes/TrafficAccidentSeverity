{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a7eab2e",
   "metadata": {},
   "source": [
    "## 02. Data Preprocessing: Feature Exclusion & Datetime Processing\n",
    "\n",
    "**Objective:** Drop outcome-related, identifier, and redundant datetime features; parse and combine date and time into a single datetime column.\n",
    "\n",
    "**PRD References:**\n",
    "- 4.3 Features to Exclude\n",
    "- 3.1.2 Data Cleaning & Preprocessing\n",
    "\n",
    "**Notebook:** 02_data_preprocessing.ipynb (Part 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "803762cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data: 22072 rows, 26 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load raw dataset\n",
    "data_path = '../data/raw/RTA_EDSA_2007-2016.csv'\n",
    "try:\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Loaded data: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"Could not find data at {data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bbe3f3",
   "metadata": {},
   "source": [
    "### 1. Drop Outcome-Related Features\n",
    "\n",
    "To avoid data leakage, we remove all casualty-related columns (`killed_*`, `injured_*`) and total counts, since our target will be defined separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "950f7dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping outcome columns: 16 columns remain\n"
     ]
    }
   ],
   "source": [
    "# List of casualty and outcome-related columns to drop\n",
    "outcome_cols = [\n",
    "    'killed_driver', 'killed_passenger', 'killed_pedestrian',\n",
    "    'injured_driver', 'injured_passenger', 'injured_pedestrian',\n",
    "    'killed_uncategorized', 'injured_uncategorized',\n",
    "    'killed_total', 'injured_total'\n",
    "]\n",
    "# Drop if present\n",
    "df.drop(columns=[c for c in outcome_cols if c in df.columns], inplace=True)\n",
    "print(f\"After dropping outcome columns: {df.shape[1]} columns remain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f332663",
   "metadata": {},
   "source": [
    "### 2. Drop Identifier and Redundant Columns\n",
    "\n",
    "Remove identifiers and address fields, as well as redundant datetime PST column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e5d8d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping identifiers & redundant datetime: 12 columns remain\n"
     ]
    }
   ],
   "source": [
    "# Identifier, address, and redundant datetime columns\n",
    "drop_cols = ['INCIDENTDETAILS_ID', 'LOCATION_TEXT', 'ADDRESS', 'DATETIME_PST']\n",
    "# Drop only existing\n",
    "df.drop(columns=[c for c in drop_cols if c in df.columns], inplace=True)\n",
    "print(f\"After dropping identifiers & redundant datetime: {df.shape[1]} columns remain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd125384",
   "metadata": {},
   "source": [
    "### 3. Parse and Combine Date and Time\n",
    "\n",
    "Convert `DATE_UTC` and `TIME_UTC` into a single `DATETIME_UTC` column for downstream processing, then drop the originals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9e1679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After parsing datetime: 11 columns remain\n",
      "0   2014-06-30 05:40:00\n",
      "1   2014-03-17 01:00:00\n",
      "2   2013-11-26 02:00:00\n",
      "3   2013-10-26 13:00:00\n",
      "4   2013-06-26 23:30:00\n",
      "Name: DATETIME_UTC, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Parse DATETIME_UTC\n",
    "df['DATETIME_UTC'] = pd.to_datetime(df['DATE_UTC'].astype(str) + ' ' + df['TIME_UTC'].astype(str), errors='coerce')\n",
    "\n",
    "# Drop original date and time columns\n",
    "for col in ['DATE_UTC', 'TIME_UTC']:\n",
    "    if col in df.columns:\n",
    "        df.drop(columns=col, inplace=True)\n",
    "\n",
    "print(f\"After parsing datetime: {df.shape[1]} columns remain\")\n",
    "print(df['DATETIME_UTC'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169e88db",
   "metadata": {},
   "source": [
    "### 4. Temporal Feature Engineering\n",
    "\n",
    "In this section, we extract various temporal features from the `DATETIME_UTC` column, including hour of day, day of week, month, year, season, and weekend flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fe758cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal features added:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "      <td>False</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>False</td>\n",
       "      <td>Spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>2013</td>\n",
       "      <td>False</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>True</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "      <td>2013</td>\n",
       "      <td>False</td>\n",
       "      <td>Summer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hour  day_of_week  day  month  year  is_weekend  season\n",
       "0     5            0   30      6  2014       False  Summer\n",
       "1     1            0   17      3  2014       False  Spring\n",
       "2     2            1   26     11  2013       False    Fall\n",
       "3    13            5   26     10  2013        True    Fall\n",
       "4    23            2   26      6  2013       False  Summer"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract temporal features from DATETIME_UTC\n",
    "if 'df' in locals():\n",
    "    df['hour'] = df['DATETIME_UTC'].dt.hour\n",
    "    df['day_of_week'] = df['DATETIME_UTC'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "    df['day'] = df['DATETIME_UTC'].dt.day\n",
    "    df['month'] = df['DATETIME_UTC'].dt.month\n",
    "    df['year'] = df['DATETIME_UTC'].dt.year\n",
    "    df['is_weekend'] = df['day_of_week'] >= 5\n",
    "\n",
    "    # Define season mapping\n",
    "    def get_season(month):\n",
    "        if month in [12, 1, 2]:\n",
    "            return 'Winter'\n",
    "        elif month in [3, 4, 5]:\n",
    "            return 'Spring'\n",
    "        elif month in [6, 7, 8]:\n",
    "            return 'Summer'\n",
    "        else:\n",
    "            return 'Fall'\n",
    "\n",
    "    df['season'] = df['month'].apply(get_season)\n",
    "\n",
    "    print(\"Temporal features added:\")\n",
    "    display(df[['hour', 'day_of_week', 'day', 'month', 'year', 'is_weekend', 'season']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d903feb",
   "metadata": {},
   "source": [
    "### 5. Verify Temporal Feature Data Types\n",
    "\n",
    "Check that the new temporal features have correct data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ef46895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour            int32\n",
      "day_of_week     int32\n",
      "day             int32\n",
      "month           int32\n",
      "year            int32\n",
      "is_weekend       bool\n",
      "season         object\n",
      "dtype: object\n",
      "\n",
      "Any null values in temporal features:\n",
      "hour           0\n",
      "day_of_week    0\n",
      "month          0\n",
      "season         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if 'df' in locals():\n",
    "    print(df[['hour', 'day_of_week', 'day', 'month', 'year', 'is_weekend', 'season']].dtypes)\n",
    "    print(\"\\nAny null values in temporal features:\")\n",
    "    print(df[['hour', 'day_of_week', 'month', 'season']].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a2d50d",
   "metadata": {},
   "source": [
    "**Next Steps (Part 2):** Temporal feature engineering (hour, day of week, month, season, etc.) in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ebeb99",
   "metadata": {},
   "source": [
    "### 6. Missing Value Handling\n",
    "\n",
    "Analyze and impute missing values for categorical features such as `WEATHER`, `LIGHT`, `MAIN_CAUSE`, `COLLISION_TYPE`, and `REPORTING_AGENCY`. Fill missing entries with 'Unknown' and document the strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61980646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before imputation:\n",
      "WEATHER             21768\n",
      "LIGHT               21768\n",
      "MAIN_CAUSE          21768\n",
      "COLLISION_TYPE          0\n",
      "REPORTING_AGENCY        0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after imputation:\n",
      "WEATHER             0\n",
      "LIGHT               0\n",
      "MAIN_CAUSE          0\n",
      "COLLISION_TYPE      0\n",
      "REPORTING_AGENCY    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# List of categorical columns to check and impute\n",
    "cat_cols = ['WEATHER', 'LIGHT', 'MAIN_CAUSE', 'COLLISION_TYPE', 'REPORTING_AGENCY']\n",
    "\n",
    "# Display missing value counts before imputation\n",
    "print(\"Missing values before imputation:\")\n",
    "print(df[cat_cols].isnull().sum())\n",
    "\n",
    "# Impute missing categorical values with 'Unknown'\n",
    "for col in cat_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "# Verify missing values after imputation\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(df[cat_cols].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f7e65b",
   "metadata": {},
   "source": [
    "**Strategy:** Imputed missing categorical entries with 'Unknown' to preserve all records and explicitly flag missing data. This approach avoids bias from mode imputation and maintains consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6a5a77",
   "metadata": {},
   "source": [
    "### 7. Next Steps (Part 4)\n",
    "\n",
    "Encode categorical features (`ROAD`, `MAIN_CAUSE`, `COLLISION_TYPE`, `WEATHER`, `LIGHT`) using One-Hot Encoding or other suitable techniques. Ensure documentation of choices and rationale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12570f4",
   "metadata": {},
   "source": [
    "### 8. Categorical Feature Encoding\n",
    "\n",
    "Encode categorical features (`ROAD`, `MAIN_CAUSE`, `COLLISION_TYPE`, `WEATHER`, `LIGHT`, `REPORTING_AGENCY`) using One-Hot Encoding to convert them into numeric indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11b69ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After encoding categorical features, dataframe has 41 columns\n"
     ]
    }
   ],
   "source": [
    "# Perform One-Hot Encoding on selected categorical columns\n",
    "cat_encode_cols = ['ROAD', 'MAIN_CAUSE', 'COLLISION_TYPE', 'WEATHER', 'LIGHT', 'REPORTING_AGENCY']\n",
    "encode_list = [col for col in cat_encode_cols if col in df.columns]\n",
    "df = pd.get_dummies(df, columns=encode_list, prefix=encode_list, dummy_na=False)\n",
    "print(f\"After encoding categorical features, dataframe has {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e095975",
   "metadata": {},
   "source": [
    "### 9. Verify Encoding Results\n",
    "\n",
    "Inspect a sample of the newly created dummy columns to ensure correct encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "053c2dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROAD_EDSA</th>\n",
       "      <th>MAIN_CAUSE_Human error</th>\n",
       "      <th>MAIN_CAUSE_Other (see description)</th>\n",
       "      <th>MAIN_CAUSE_Road defect</th>\n",
       "      <th>MAIN_CAUSE_Unknown</th>\n",
       "      <th>MAIN_CAUSE_Vehicle defect</th>\n",
       "      <th>COLLISION_TYPE_Angle Impact</th>\n",
       "      <th>COLLISION_TYPE_Head-On</th>\n",
       "      <th>COLLISION_TYPE_Hit Object</th>\n",
       "      <th>COLLISION_TYPE_Multiple</th>\n",
       "      <th>...</th>\n",
       "      <th>WEATHER_partly-cloudy-day</th>\n",
       "      <th>WEATHER_partly-cloudy-night</th>\n",
       "      <th>WEATHER_rain</th>\n",
       "      <th>LIGHT_Unknown</th>\n",
       "      <th>LIGHT_day</th>\n",
       "      <th>LIGHT_dusk</th>\n",
       "      <th>LIGHT_night</th>\n",
       "      <th>REPORTING_AGENCY_MMDA Metrobase</th>\n",
       "      <th>REPORTING_AGENCY_MMDA Road Safety Unit</th>\n",
       "      <th>REPORTING_AGENCY_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ROAD_EDSA  MAIN_CAUSE_Human error  MAIN_CAUSE_Other (see description)  \\\n",
       "0       True                    True                               False   \n",
       "1       True                    True                               False   \n",
       "2       True                    True                               False   \n",
       "3       True                    True                               False   \n",
       "4       True                    True                               False   \n",
       "\n",
       "   MAIN_CAUSE_Road defect  MAIN_CAUSE_Unknown  MAIN_CAUSE_Vehicle defect  \\\n",
       "0                   False               False                      False   \n",
       "1                   False               False                      False   \n",
       "2                   False               False                      False   \n",
       "3                   False               False                      False   \n",
       "4                   False               False                      False   \n",
       "\n",
       "   COLLISION_TYPE_Angle Impact  COLLISION_TYPE_Head-On  \\\n",
       "0                        False                   False   \n",
       "1                        False                   False   \n",
       "2                        False                   False   \n",
       "3                        False                   False   \n",
       "4                        False                   False   \n",
       "\n",
       "   COLLISION_TYPE_Hit Object  COLLISION_TYPE_Multiple  ...  \\\n",
       "0                      False                    False  ...   \n",
       "1                      False                    False  ...   \n",
       "2                      False                    False  ...   \n",
       "3                      False                    False  ...   \n",
       "4                      False                    False  ...   \n",
       "\n",
       "   WEATHER_partly-cloudy-day  WEATHER_partly-cloudy-night  WEATHER_rain  \\\n",
       "0                      False                        False         False   \n",
       "1                      False                        False         False   \n",
       "2                      False                        False         False   \n",
       "3                      False                        False         False   \n",
       "4                      False                        False         False   \n",
       "\n",
       "   LIGHT_Unknown  LIGHT_day  LIGHT_dusk  LIGHT_night  \\\n",
       "0           True      False       False        False   \n",
       "1           True      False       False        False   \n",
       "2           True      False       False        False   \n",
       "3           True      False       False        False   \n",
       "4           True      False       False        False   \n",
       "\n",
       "   REPORTING_AGENCY_MMDA Metrobase  REPORTING_AGENCY_MMDA Road Safety Unit  \\\n",
       "0                            False                                    True   \n",
       "1                            False                                    True   \n",
       "2                            False                                    True   \n",
       "3                            False                                    True   \n",
       "4                            False                                    True   \n",
       "\n",
       "   REPORTING_AGENCY_Other  \n",
       "0                   False  \n",
       "1                   False  \n",
       "2                   False  \n",
       "3                   False  \n",
       "4                   False  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total encoded features: 29\n"
     ]
    }
   ],
   "source": [
    "# Display a sample of the encoded dummy columns\n",
    "encoded_cols = [col for col in df.columns if any(col.startswith(pref + '_') for pref in encode_list)]\n",
    "display(df[encoded_cols].head())\n",
    "print(f\"Total encoded features: {len(encoded_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb9cb8a",
   "metadata": {},
   "source": [
    "### 10. Next Steps (Part 5)\n",
    "\n",
    "Proceed to scale numerical features (`Y`, `X`), parse `DESC` for derived features, drop or transform as needed, and save the fully preprocessed DataFrame for downstream modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a0b281",
   "metadata": {},
   "source": [
    "### 11. Numerical Feature Planning & `DESC` Parsing\n",
    "\n",
    "Plan for numerical scaling in the modeling pipeline (e.g., fit scaler on `X_train`).\n",
    "Here we derive basic features from the `DESC` text column: word count and presence of the word \"collision\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5268c97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derived DESC features and dropped original DESC column.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc_word_count</th>\n",
       "      <th>desc_contains_collision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   desc_word_count  desc_contains_collision\n",
       "0               30                        1\n",
       "1               38                        1\n",
       "2               30                        1\n",
       "3               31                        1\n",
       "4               32                        1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse basic features from DESC\n",
    "if 'df' in locals() and 'DESC' in df.columns:\n",
    "    df['desc_word_count'] = df['DESC'].astype(str).str.split().apply(len)\n",
    "    df['desc_contains_collision'] = df['DESC'].str.contains('collision', case=False, na=False).astype(int)\n",
    "    # Drop original DESC column\n",
    "    df.drop(columns=['DESC'], inplace=True)\n",
    "    print(\"Derived DESC features and dropped original DESC column.\")\n",
    "    display(df[['desc_word_count', 'desc_contains_collision']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da305b06",
   "metadata": {},
   "source": [
    "### 12. Save Fully Preprocessed DataFrame\n",
    "\n",
    "Save the cleaned and feature-engineered DataFrame for use in downstream modeling notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a378c8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to '../data/processed/preprocessed_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Ensure output directory exists and save\n",
    "import os\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "df.to_csv('../data/processed/preprocessed_data.csv', index=False)\n",
    "print(\"Preprocessed data saved to '../data/processed/preprocessed_data.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic-severity",
   "language": "python",
   "name": "trafficseverity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
